{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73090434-03f3-401b-a5c0-025f6d5d5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, VecMonitor\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b783b9-bc5f-4625-aebe-c517c5bf7c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773c7a9c-8bc0-4232-8917-075117722e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"ALE/Superman-v5\", \n",
    "#                render_mode=None,\n",
    "#                frameskip=4,\n",
    "#                full_action_space=False)\n",
    "\n",
    "# print(\"Environment created!\")\n",
    "# print(\"Action space:\", env.action_space)\n",
    "# print(\"Observation space:\", env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e1785f-9309-47b5-9e16-01bcca0d249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize PPO model with optimized parameters for Atari\n",
    "# model = PPO(\n",
    "#     policy=\"CnnPolicy\",           # Use CNN for pixel input\n",
    "#     env=env,\n",
    "#     learning_rate=2.5e-4,         # Adam learning rate\n",
    "#     n_steps=128,                  # Steps per environment per update\n",
    "#     batch_size=256,               # Minibatch size\n",
    "#     n_epochs=4,                   # Number of epoch when optimizing the surrogate\n",
    "#     gamma=0.99,                   # Discount factor\n",
    "#     gae_lambda=0.95,              # Factor for trade-off of bias vs variance\n",
    "#     clip_range=0.1,               # Surrogate clipping coefficient\n",
    "#     clip_range_vf=None,           # Value function clipping (None for auto)\n",
    "#     normalize_advantage=True,     # Normalize advantages\n",
    "#     ent_coef=0.01,                # Entropy coefficient (encourages exploration)\n",
    "#     vf_coef=0.5,                  # Value function coefficient in loss\n",
    "#     max_grad_norm=0.5,            # Maximum gradient norm\n",
    "#     tensorboard_log=\"./ppo_superman_tensorboard/\",  # Log for TensorBoard\n",
    "#     verbose=1                     # Print training progress\n",
    "# )\n",
    "\n",
    "# print(\"PPO model created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2d2fc9-5a0d-46bc-ac26-d5342ef8f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# print(\"Starting PPO training...\")\n",
    "# # 1M steps\n",
    "# model.learn(total_timesteps=1000000)\n",
    "\n",
    "# print(\"PPO training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5808ca12-be47-43d2-9ce4-f6440d8ed46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment properly\n",
    "def make_env():\n",
    "    env = gym.make(\"ALE/Superman-v5\")\n",
    "    env = Monitor(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b046b0fe-c7ee-4a4e-8ca2-1054b7fb1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a stacked environment for CNN processing\n",
    "# env = make_atari_env(\"ALE/Superman-v5\", n_envs=1, seed=0)\n",
    "# env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d4819be-6b14-4021-8e26-f53be35952fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "992efcd4-f254-4c75-9e1c-24e604ae8a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 187  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 10   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 65         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01176833 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.88      |\n",
      "|    explained_variance   | -23.9      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0578    |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    value_loss           | 3.77       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014395973 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | -1.44       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0425     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.00141     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1b884ba04c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_timesteps = 10000000    # 10M\n",
    "# total_timesteps =  2000000    # 2M\n",
    "# total_timesteps =  1000000    # 1M\n",
    "# total_timesteps =   100000    # 100K\n",
    "# total_timesteps =    10000    # 10K\n",
    "total_timesteps =     5000    # 5K\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50485ee6-f72c-48ed-a122-1af6bc4053a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "Episode rewards: []\n",
      "Episode lengths: []\n",
      "Number of episodes: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training completed!\")\n",
    "print(f\"Episode rewards: {env.get_episode_rewards()}\")\n",
    "print(f\"Episode lengths: {env.get_episode_lengths()}\")\n",
    "print(f\"Number of episodes: {len(env.get_episode_lengths())}\")\n",
    "if len(env.get_episode_lengths()) > 0:\n",
    "    print(f\"Average episode length: {np.mean(env.get_episode_lengths())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6f94f-c0ac-4ac6-b974-7f739eb632a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a9289-6c7b-4fdf-b743-4d8e18c36495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955afd6-f19d-4bb7-8f34-8e16558b4bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac649c0-a8f7-4ae8-8918-58e57cd9ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"ppo_superman\")\n",
    "print(\"PPO model saved as 'ppo_superman'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c8ab8c1-4f98-4770-8d0a-beabd4be2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8eb5af-e7fa-4d73-b8c6-554255f2bfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1576a-1e5c-4902-b9cc-26970fa39107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197dcb70-a257-40cd-9770-f15e2562505f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
