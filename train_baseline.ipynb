{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f1ba4b-bf1e-42d7-8965-96bb00d6230e",
   "metadata": {},
   "source": [
    "# BASELINE\n",
    "Logan Wong\n",
    "\n",
    "law3082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5b89fa-7719-4264-9d51-070499741082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import numpy as np\n",
    "import time\n",
    "from stable_baselines3 import DQN\t\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a80c1-3947-4dfe-8057-8372069643f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4f6dae6-9159-4be8-90eb-6f3a9945b2be",
   "metadata": {},
   "source": [
    "## Test to make sure no errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97a260-acfa-4913-af87-deead22e9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"ALE/Superman-v5\", render_mode=None)\n",
    "\n",
    "# action_space = env.action_space\n",
    "# obs_space = env.observation_space\n",
    "# print(\"Action space:\", action_space)\n",
    "# print(\"Number of actions:\", action_space.n)\n",
    "# print(\"Action meanings:\", env.unwrapped.get_action_meanings())\n",
    "# print(\"\\nObservation space:\", obs_space)\n",
    "\n",
    "# obs, _ = env.reset()\n",
    "# print(\"Observation shape:\", obs.shape)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433ba55-8ea6-4af1-9466-89a6016d4007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c80a1d56-8398-4d27-9e15-a341d01c45dd",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7de14c5-c99c-46ef-9a04-da0a87162de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Superman environment\n",
    "# And enable visual rendering so humans can SEE it\n",
    "# RENDER_MODE = \"human\"\n",
    "RENDER_MODE = None\n",
    "\n",
    "env = gym.make(\"ALE/Superman-v5\", render_mode=RENDER_MODE, frameskip=4, full_action_space=False)\n",
    "# NOTICE: A python window appears if render_mode is human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c8176-b745-445c-8420-954f3ea7b55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13989600-f599-4cc8-8a12-4c7a15e99af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3279659c-9e53-4db4-b1d9-1505bc1dc27a",
   "metadata": {},
   "source": [
    "## Init DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8feb78-117d-4521-b823-ab4555664ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n",
      "C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 4.03GB > 3.32GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN model created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Policy: I tell it to use a CNN\n",
    "# env: Pass in the environment\n",
    "# Learing rat: Alpha = 0.0001\n",
    "model = DQN(\n",
    "    policy=\"CnnPolicy\",\n",
    "    env=env,\n",
    "    learning_rate= 0.0001,\n",
    "    # buffer_size=100000,\n",
    "    buffer_size=20000,\n",
    "    batch_size=32,\n",
    "    target_update_interval=1000,\n",
    "    verbose=1  \n",
    ")\n",
    "\n",
    "print(\"DQN model created successfully!\")\n",
    "\n",
    "# Output:\n",
    "# Using cpu device\n",
    "# Wrapping the env with a `Monitor` wrapper\n",
    "# Wrapping the env in a DummyVecEnv.\n",
    "# Wrapping the env in a VecTransposeImage.\n",
    "# C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
    "#   warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n",
    "# C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 20.16GB > 4.78GB\n",
    "#   warnings.warn("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167dc8c2-69b9-438a-b791-3f8e8e452f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1abd42f-2cf2-4ec8-a91f-8084c08bd122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56ad093e-648f-4117-b17b-7d67a1c31aac",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b368651f-ddf9-4b1b-ac6d-e11e1bd12a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training phase completed!\n"
     ]
    }
   ],
   "source": [
    "# total_timesteps = 100000\n",
    "# total_timesteps = 10000\n",
    "total_timesteps = 5000\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "print(\"Training phase completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a4008-74d4-42e2-a7f3-b737148af61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bcaa8c-60aa-4a83-80e0-cd88c8c8f9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80db4e-1355-4938-bcb6-3fe2c53fb93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9bda9-e379-464c-b17e-2723c8bacaec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61dd8de-f44b-455b-b878-b60a547e7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the policy network\n",
    "model.policy.save(\"dqn_superman_policy\")\n",
    "print(\"Policy network saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14489d-d35d-4e12-90c3-2069589093e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ec284-41a7-43bf-99ea-98155c65fec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3fd02-e8ca-46f5-ba78-8bb9c373d01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e29d9-aec3-4339-b13b-92ef35c534e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae0737ab-2697-421e-acd8-b6e83a434af5",
   "metadata": {},
   "source": [
    "## Plot episode rewards from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412765e-c17e-4b2c-9431-779a3fb4073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(model.ep_info_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc82591-4a30-48a2-a480-e938950532f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of episodes recorded: {len(model.ep_info_buffer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee1234-7b5c-40c8-839c-3e8b727da11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 episodes in buffer:\")\n",
    "for i, episode_info in enumerate(list(model.ep_info_buffer)[:5]):\n",
    "    print(f\"Episode {i}: {episode_info}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c2dd5-e754-425b-9639-d69799bf5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rewards and episode lengths from the buffer\n",
    "if len(model.ep_info_buffer) > 0:\n",
    "    rewards = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    for episode_info in model.ep_info_buffer:\n",
    "        # get episode's reward\n",
    "        rewards.append(episode_info['r'])  \n",
    "        # get episode's length aka number of steps\n",
    "        episode_lengths.append(episode_info['l'])  \n",
    "    \n",
    "    # Create the learning curve plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Reward over episodes\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel('Training Episode')\n",
    "    plt.ylabel('Episode Reward')\n",
    "    plt.title('DQN Learning Curve\\n(Higher is Better)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 2: Episode length over episodes  \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(episode_lengths)\n",
    "    plt.xlabel('Training Episode')\n",
    "    plt.ylabel('Episode Length (Steps)')\n",
    "    plt.title('Episode Duration\\n(Longer survival may indicate learning)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\nTraining Summary:\")\n",
    "    print(f\"Total training episodes: {len(rewards)}\")\n",
    "    print(f\"Final average reward: {sum(rewards[-10:])/10:.2f} (last 10 episodes)\")\n",
    "    print(f\"Best episode reward: {max(rewards):.2f}\")\n",
    "    print(f\"Average episode length: {sum(episode_lengths)/len(episode_lengths):.1f} steps\")\n",
    "    \n",
    "else:\n",
    "    print(\"No episode data found in the buffer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92375ae8-362f-44fa-8c6f-7620497248e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760d358-a98e-401c-8f8b-5ac1fb6b863a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1c50d-9460-4ff8-9918-5dada2ec53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(model.ep_info_buffer['r'])  \n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Reward')\n",
    "# plt.title('DQN Learning Curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e1521-e3a9-48b5-84a0-494b30a12b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bf0ad-8118-4ce7-90cf-13e4dea7c9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
