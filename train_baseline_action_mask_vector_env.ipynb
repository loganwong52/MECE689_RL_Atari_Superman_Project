{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f1ba4b-bf1e-42d7-8965-96bb00d6230e",
   "metadata": {},
   "source": [
    "# BASELINE\n",
    "Logan Wong\n",
    "\n",
    "law3082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5b89fa-7719-4264-9d51-070499741082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\t\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import torch\n",
    "\n",
    "# For debugging\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import time\n",
    "\n",
    "# Action masking\n",
    "from gymnasium import ActionWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6dae6-9159-4be8-90eb-6f3a9945b2be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test to make sure no errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b97a260-acfa-4913-af87-deead22e9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"ALE/Superman-v5\", render_mode=None)\n",
    "\n",
    "# action_space = env.action_space\n",
    "# obs_space = env.observation_space\n",
    "# print(\"Action space:\", action_space)\n",
    "# print(\"Number of actions:\", action_space.n)\n",
    "# action_meanings = env.unwrapped.get_action_meanings()\n",
    "# print(\"Action meanings:\", action_meanings)\n",
    "# print(\"\\nObservation space:\", obs_space)\n",
    "\n",
    "# obs, _ = env.reset()\n",
    "# print(\"Observation shape:\", obs.shape)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f433ba55-8ea6-4af1-9466-89a6016d4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # action_meanings\n",
    "# action_dict = {}\n",
    "# for i in range(len(action_meanings)):\n",
    "#     action_dict[i] = action_meanings[i]\n",
    "\n",
    "# print(action_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80aa947d-4974-4867-80a4-8422c3780588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a in list(action_dict.keys()):\n",
    "#     print(f\"{a}: {action_dict[a]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26a6178-9cba-4829-9d2a-4abcb52df85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action meanings: ['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n",
    "\n",
    "# {0: 'NOOP', 1: 'FIRE', 2: 'UP', 3: 'RIGHT', 4: 'LEFT', 5: 'DOWN', 6: 'UPRIGHT', 7: 'UPLEFT', 8: 'DOWNRIGHT', 9: 'DOWNLEFT', 10: 'UPFIRE', 11: 'RIGHTFIRE', 12: 'LEFTFIRE', 13: 'DOWNFIRE', 14: 'UPRIGHTFIRE', 15: 'UPLEFTFIRE', 16: 'DOWNRIGHTFIRE', 17: 'DOWNLEFTFIRE'}\n",
    "\n",
    "# # ACTIONS\n",
    "# 0: NOOP\n",
    "# 1: FIRE\n",
    "\n",
    "# 2: UP\n",
    "# 3: RIGHT\n",
    "# 4: LEFT\n",
    "# 5: DOWN\n",
    "# 6: UPRIGHT\n",
    "# 7: UPLEFT\n",
    "# 8: DOWNRIGHT\n",
    "# 9: DOWNLEFT\n",
    "\n",
    "# 10: UPFIRE\n",
    "# 11: RIGHTFIRE\n",
    "# 12: LEFTFIRE\n",
    "# 13: DOWNFIRE\n",
    "\n",
    "# 14: UPRIGHTFIRE\n",
    "# 15: UPLEFTFIRE\n",
    "# 16: DOWNRIGHTFIRE\n",
    "# 17: DOWNLEFTFIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a1d56-8398-4d27-9e15-a341d01c45dd",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972a80c1-3947-4dfe-8057-8372069643f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupermanActionReducer(ActionWrapper):\n",
    "    def __init__(self, env, allowed_actions=None):\n",
    "        super().__init__(env)\n",
    "        \n",
    "        if allowed_actions is None:\n",
    "            # Basic movement only: Cardinal directions & diagonal directions\n",
    "            allowed_actions = [2,3,4,5, 6,7,8,9]\n",
    "            \n",
    "            # Cardinal directions, diagonal directions, AND x-ray vision\n",
    "            # allowed_actions = [2,3,4,5, 6,7,8,9, 10,11,12,13]\n",
    "        \n",
    "        self.allowed_actions = allowed_actions\n",
    "        self.action_space = gym.spaces.Discrete(len(allowed_actions))\n",
    "        \n",
    "    def action(self, action):\n",
    "        # Map the reduced action index back to the original action\n",
    "        return self.allowed_actions[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63492b1e-17cd-4a87-96ce-f8e018334965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    \n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7de14c5-c99c-46ef-9a04-da0a87162de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Superman environment\n",
    "# And enable visual rendering so humans can SEE it\n",
    "# RENDER_MODE = \"human\"\n",
    "RENDER_MODE = None\n",
    "\n",
    "env = gym.make(\"ALE/Superman-v5\", render_mode=None)\n",
    "env = SupermanActionReducer(env)\n",
    "\n",
    "# Wrap the environment with Monitor to print out progress\n",
    "# env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680c8176-b745-445c-8420-954f3ea7b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment type: <class '__main__.SupermanActionReducer'>\n",
      "Is vectorized? False\n"
     ]
    }
   ],
   "source": [
    "# Check environment type\n",
    "print(\"Environment type:\", type(env))\n",
    "print(\"Is vectorized?\", hasattr(env, 'num_envs'))\n",
    "\n",
    "if hasattr(env, 'num_envs'):\n",
    "    print(\"Number of parallel environments:\", env.num_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13989600-f599-4cc8-8a12-4c7a15e99af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3279659c-9e53-4db4-b1d9-1505bc1dc27a",
   "metadata": {},
   "source": [
    "## Init DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e58a3180-0fda-4106-884d-7d5ef254acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f8feb78-117d-4521-b823-ab4555664ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN model created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Policy: I tell it to use a CNN\n",
    "# env: Pass in the environment\n",
    "# Learing rat: Alpha = 0.0001\n",
    "model = DQN(\n",
    "    policy=\"CnnPolicy\",\n",
    "    env=env,\n",
    "    learning_rate= 0.0001,\n",
    "    # buffer_size=100000,\n",
    "    buffer_size=20000,\n",
    "    batch_size=32,\n",
    "    target_update_interval=1000,\n",
    "    verbose=1,\n",
    "    device=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"DQN model created successfully!\")\n",
    "\n",
    "# Output:\n",
    "# Using cpu device\n",
    "# Wrapping the env with a `Monitor` wrapper\n",
    "# Wrapping the env in a DummyVecEnv.\n",
    "# Wrapping the env in a VecTransposeImage.\n",
    "# C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:78: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
    "#   warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n",
    "# C:\\Users\\Logan\\anaconda3\\envs\\superman_env\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 20.16GB > 4.78GB\n",
    "#   warnings.warn("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1abd42f-2cf2-4ec8-a91f-8084c08bd122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56ad093e-648f-4117-b17b-7d67a1c31aac",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1535bce4-6dba-47b7-b8d9-e2ccb0c0c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressCallback(BaseCallback):\n",
    "    def __init__(self, print_freq=1000):\n",
    "        super().__init__()\n",
    "        self.print_freq = print_freq\n",
    "        self.last_print = 0\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        if self.num_timesteps - self.last_print >= self.print_freq:\n",
    "            # Print progress every print_freq steps\n",
    "            elapsed = time.time() - self.start_time\n",
    "            steps_per_sec = self.num_timesteps / elapsed\n",
    "            \n",
    "            # Get latest episode info if available\n",
    "            episode_info = \"\"\n",
    "            if hasattr(self.model, 'ep_info_buffer') and len(self.model.ep_info_buffer) > 0:\n",
    "                latest = self.model.ep_info_buffer[-1]\n",
    "                episode_info = f\" | Latest episode: {latest['l']} steps, {latest['r']} reward\"\n",
    "            \n",
    "            print(f\"Step {self.num_timesteps} | Speed: {steps_per_sec:.1f} steps/sec{episode_info}\")\n",
    "            self.last_print = self.num_timesteps\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b368651f-ddf9-4b1b-ac6d-e11e1bd12a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 | Speed: 36.8 steps/sec\n",
      "Step 2000 | Speed: 33.7 steps/sec\n",
      "Step 3000 | Speed: 31.1 steps/sec\n",
      "Step 4000 | Speed: 28.9 steps/sec\n",
      "Step 5000 | Speed: 27.8 steps/sec\n",
      "Step 6000 | Speed: 27.0 steps/sec\n",
      "Step 7000 | Speed: 26.5 steps/sec\n",
      "Step 8000 | Speed: 25.9 steps/sec\n",
      "Step 9000 | Speed: 25.6 steps/sec\n",
      "Step 10000 | Speed: 24.4 steps/sec\n",
      "Training phase completed!\n",
      "Time taken: 0:06:49\n",
      "Speed: 24.41 steps/second\n"
     ]
    }
   ],
   "source": [
    "# total_timesteps = 10000000    # 10M\n",
    "# total_timesteps =  2000000    # 2M\n",
    "# total_timesteps =  1000000    # 1M\n",
    "# total_timesteps =   100000    # 100K\n",
    "# total_timesteps =    10000    # 10K\n",
    "total_timesteps =     5000    # 5K\n",
    "\n",
    "# ALSO: Time how long it takes\n",
    "print(\"Training phase started.\")\n",
    "start_time = time.time()\n",
    "# model.learn(total_timesteps=total_timesteps)\n",
    "model.learn(total_timesteps=total_timesteps, callback=ProgressCallback(print_freq=1000))\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "time_in_minutes_and_seconds = convert(training_duration)\n",
    "\n",
    "print(\"Training phase completed!\")\n",
    "print(f\"Time taken: {time_in_minutes_and_seconds}\")\n",
    "print(f\"Speed: {total_timesteps/training_duration:.2f} steps/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227a4008-74d4-42e2-a7f3-b737148af61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80db4e-1355-4938-bcb6-3fe2c53fb93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d61dd8de-f44b-455b-b878-b60a547e7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy network saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Save the policy network\n",
    "model.policy.save(\"dqn_superman_policy\")\n",
    "print(\"Policy network saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14489d-d35d-4e12-90c3-2069589093e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ec284-41a7-43bf-99ea-98155c65fec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3fd02-e8ca-46f5-ba78-8bb9c373d01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e29d9-aec3-4339-b13b-92ef35c534e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae0737ab-2697-421e-acd8-b6e83a434af5",
   "metadata": {},
   "source": [
    "## Plot episode rewards from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d412765e-c17e-4b2c-9431-779a3fb4073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.deque'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model.ep_info_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fc82591-4a30-48a2-a480-e938950532f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes recorded: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of episodes recorded: {len(model.ep_info_buffer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aee1234-7b5c-40c8-839c-3e8b727da11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 episodes in buffer:\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 episodes in buffer:\")\n",
    "for i, episode_info in enumerate(list(model.ep_info_buffer)[:5]):\n",
    "    print(f\"Episode {i}: {episode_info}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a8c2dd5-e754-425b-9639-d69799bf5d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No episode data found in the buffer.\n"
     ]
    }
   ],
   "source": [
    "# Extract rewards and episode lengths from the buffer\n",
    "if len(model.ep_info_buffer) > 0:\n",
    "    rewards = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    for episode_info in model.ep_info_buffer:\n",
    "        # get episode's reward\n",
    "        rewards.append(episode_info['r'])  \n",
    "        # get episode's length aka number of steps\n",
    "        episode_lengths.append(episode_info['l'])  \n",
    "    \n",
    "    # Create the learning curve plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Reward over episodes\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel('Training Episode')\n",
    "    plt.ylabel('Episode Reward')\n",
    "    plt.title('DQN Learning Curve\\n(Higher is Better)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 2: Episode length over episodes  \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(episode_lengths)\n",
    "    plt.xlabel('Training Episode')\n",
    "    plt.ylabel('Episode Length (Steps)')\n",
    "    plt.title('Episode Duration\\n(Longer survival may indicate learning)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"\\nTraining Summary:\")\n",
    "    print(f\"Total training episodes: {len(rewards)}\")\n",
    "    print(f\"Final average reward: {sum(rewards[-10:])/10:.2f} (last 10 episodes)\")\n",
    "    print(f\"Best episode reward: {max(rewards):.2f}\")\n",
    "    print(f\"Average episode length: {sum(episode_lengths)/len(episode_lengths):.1f} steps\")\n",
    "    \n",
    "else:\n",
    "    print(\"No episode data found in the buffer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92375ae8-362f-44fa-8c6f-7620497248e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760d358-a98e-401c-8f8b-5ac1fb6b863a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bf0ad-8118-4ce7-90cf-13e4dea7c9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
